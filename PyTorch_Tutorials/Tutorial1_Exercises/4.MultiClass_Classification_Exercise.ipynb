{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Multi-Class Image Classification\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maheshghanta/Codes/blob/master/PyTorch_Tutorials/Tutorial1_Exercises/4.MultiClass_Classification_Exercise.ipynb)\n",
    "\n",
    "This tutorial demonstrates building a **Convolutional Neural Network (CNN)** for CIFAR-10 image classification with:\n",
    "- CNN architecture with convolutional and pooling layers\n",
    "- Complete training pipeline\n",
    "- TensorBoard logging\n",
    "- Comprehensive metrics and visualization"
   ],
   "id": "ce0c77bcadf97234"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75da9ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/bin/python: No module named pip\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision\n",
    "%pip install ipywidgets\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install scipy\n",
    "%pip install -i https://test.pypi.org/simple/ exercise-validation==0.1.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We'll build a **Convolutional Neural Network (CNN)** - designed specifically for image data - to classify CIFAR-10 images.\n",
    "\n",
    "**Why CNN over MLP?**\n",
    "- **Spatial awareness**: Preserves 2D structure of images\n",
    "- **Translation invariance**: Recognizes patterns anywhere in image\n",
    "- **Parameter efficiency**: Shared weights reduce parameters\n",
    "- **Feature hierarchy**: Builds from edges â†’ shapes â†’ objects\n",
    "\n",
    "**Architecture Components:**\n",
    "- Convolutional layers: Extract spatial features\n",
    "- Pooling layers: Reduce spatial dimensions\n",
    "- Batch normalization: Stabilize training\n",
    "- Fully connected layers: Final classification"
   ],
   "id": "30e585ea05b02d7a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ],
   "id": "3606a9e1f4e0d83b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ],
   "id": "4dc365f57030276b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cbec9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Validation framework loaded successfully!\n",
      "Complete the exercises and click the 'Check Answer' button to validate your work.\n",
      "âœ“ Validation functions imported from exercise_validation package\n"
     ]
    }
   ],
   "source": [
    "from exercise_validation import (\n",
    "    validate_cnn_ex1,create_check_button,create_feedback\n",
    ")\n",
    "\n",
    "print(\"âœ“ Validation functions imported from exercise_validation package\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91866595",
   "metadata": {},
   "source": [
    "## ðŸŽ® Exercise Validation Framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad01ee",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data with Augmentation\n",
    "\n",
    "CNNs benefit greatly from data augmentation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b5ffd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 40000\n",
      "Validation samples: 10000\n",
      "Test samples: 10000\n",
      "Classes: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip horizontally\n",
    "    transforms.RandomCrop(32, padding=4),     # Random crop with padding\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),  # Color variations\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# No augmentation for validation/test\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "train_dataset_full = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Split training data into train and validation\n",
    "train_size = int(0.8 * len(train_dataset_full))\n",
    "val_size = len(train_dataset_full) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    train_dataset_full,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {test_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29512fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mghanta/Documents/Codes/Non_Core/ML_Demos/Codes/PyTorch_Tutorials/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: torch.Size([128, 3, 32, 32])\n",
      "Label shape: torch.Size([128])\n",
      "Image size: torch.Size([3, 32, 32]) = (C, H, W)\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 128\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Check data shape\n",
    "sample_image, sample_label = next(iter(train_loader))\n",
    "print(f\"Batch shape: {sample_image.shape}\")  # (batch_size, channels, height, width)\n",
    "print(f\"Label shape: {sample_label.shape}\")\n",
    "print(f\"Image size: {sample_image[0].shape} = (C, H, W)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75483edb",
   "metadata": {},
   "source": [
    "## 2. Define CNN Model\n",
    "\n",
    "We'll create a CNN with multiple convolutional blocks followed by fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b9ac136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR10_CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "Total parameters: 1,283,914\n",
      "Trainable parameters: 1,283,914\n"
     ]
    }
   ],
   "source": [
    "class CIFAR10_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network for CIFAR-10 classification\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv Block 1: 3 -> 64 channels\n",
    "    - Conv Block 2: 64 -> 128 channels  \n",
    "    - Conv Block 3: 128 -> 256 channels\n",
    "    - Fully Connected: 256 -> 10 classes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CIFAR10_CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Block 1\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 32x32 -> 16x16\n",
    "        )\n",
    "        \n",
    "        # Convolutional Block 2\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 16x16 -> 8x8\n",
    "        )\n",
    "        \n",
    "        # Convolutional Block 3\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)  # 8x8 -> 4x4\n",
    "        )\n",
    "        \n",
    "        # Global Average Pooling\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Convolutional feature extraction\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        # Global pooling\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Classification\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model = CIFAR10_CNN()\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539e3c80",
   "metadata": {},
   "source": [
    "## 3. Setup Training Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a0b26e",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Exercise 1: CNN Architecture\n",
    "\n",
    "**Task:** Build a convolutional block.\n",
    "\n",
    "**Instructions:**\n",
    "Create a conv block with:\n",
    "- Conv2d: 3â†’32 channels, kernel=3, padding=1\n",
    "- BatchNorm2d: 32 channels\n",
    "- ReLU\n",
    "- MaxPool2d: kernel=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b35c809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1648e543353c4658a8600506b7b2a607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='âœ“ Check Answer', icon='check', style=ButtonStyle(), tooltip='Clickâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48801f6109a450db478776e7e76049a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: Create conv block\n",
    "        self.conv_block = None  # nn.Sequential(Conv2d, BatchNorm2d, ReLU, MaxPool2d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.conv_block:\n",
    "            return self.conv_block(x)\n",
    "        return None\n",
    "\n",
    "my_cnn = MyCNN()\n",
    "test_input = torch.randn(4, 3, 32, 32)\n",
    "if my_cnn(test_input) is not None:\n",
    "    print(f\"Output shape: {my_cnn(test_input).shape}\")\n",
    "create_check_button(\"cnn_ex1\", lambda: validate_cnn_ex1(my_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Loss function: CrossEntropyLoss()\n",
      "Optimizer: Adam\n",
      "Initial learning rate: 0.001\n",
      "Scheduler: ReduceLROnPlateau\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer (Adam with weight decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler (ReduceLROnPlateau - reduces LR when validation loss plateaus)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")"
   ],
   "id": "304874409979379f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup TensorBoard Logging"
   ],
   "id": "dddaad4f00b87edb"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard logs saved to: runs/cnn_cifar10_20251104_184357\n",
      "To view: tensorboard --logdir=runs\n",
      "Model graph added to TensorBoard\n"
     ]
    }
   ],
   "source": [
    "# Create TensorBoard writer with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f'runs/cnn_cifar10_{timestamp}'\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs saved to: {log_dir}\")\n",
    "print(f\"To view: tensorboard --logdir=runs\")\n",
    "\n",
    "# Log model architecture\n",
    "sample_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "writer.add_graph(model, sample_input)\n",
    "print(\"Model graph added to TensorBoard\")"
   ],
   "id": "d0e37637f932d0d6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ],
   "id": "44f4049bcbd81624"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device, epoch, writer):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \n",
    "    Returns:\n",
    "        average_loss: Average training loss\n",
    "        accuracy: Training accuracy (%)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        # Move data to device\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Log batch metrics to TensorBoard\n",
    "        if batch_idx % 50 == 0:\n",
    "            writer.add_scalar('Train/BatchLoss', loss.item(), epoch * len(loader) + batch_idx)\n",
    "            batch_acc = 100. * correct / total\n",
    "            writer.add_scalar('Train/BatchAccuracy', batch_acc, epoch * len(loader) + batch_idx)\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'  Batch [{batch_idx}/{len(loader)}] | '\n",
    "                      f'Loss: {loss.item():.4f} | Acc: {batch_acc:.2f}%')\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device, epoch, writer, phase='Validation'):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \n",
    "    Returns:\n",
    "        average_loss: Average validation loss\n",
    "        accuracy: Validation accuracy (%)\n",
    "        all_preds: All predictions\n",
    "        all_labels: All true labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Log epoch metrics to TensorBoard\n",
    "    writer.add_scalar(f'{phase}/Loss', avg_loss, epoch)\n",
    "    writer.add_scalar(f'{phase}/Accuracy', accuracy, epoch)\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ],
   "id": "29a112d7eb498dfe"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop"
   ],
   "id": "da5d36dafd35ebba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 30 epochs...\n",
      "================================================================================\n",
      "\n",
      "Epoch 1/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 2.3407 | Acc: 8.59%\n",
      "  Batch [100/313] | Loss: 1.7624 | Acc: 27.62%\n",
      "  Batch [200/313] | Loss: 1.5479 | Acc: 33.56%\n",
      "  Batch [300/313] | Loss: 1.0719 | Acc: 38.31%\n",
      "\n",
      "Train Loss: 1.5965 | Train Acc: 38.77%\n",
      "Val Loss: 1.6052 | Val Acc: 44.48%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 44.48%)\n",
      "\n",
      "Epoch 2/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 1.5840 | Acc: 44.53%\n",
      "  Batch [100/313] | Loss: 1.1160 | Acc: 53.98%\n",
      "  Batch [200/313] | Loss: 1.2551 | Acc: 55.77%\n",
      "  Batch [300/313] | Loss: 1.0089 | Acc: 57.02%\n",
      "\n",
      "Train Loss: 1.1697 | Train Acc: 57.16%\n",
      "Val Loss: 1.3439 | Val Acc: 51.91%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 51.91%)\n",
      "\n",
      "Epoch 3/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 1.1832 | Acc: 53.91%\n",
      "  Batch [100/313] | Loss: 0.9306 | Acc: 62.55%\n",
      "  Batch [200/313] | Loss: 1.0162 | Acc: 64.04%\n",
      "  Batch [300/313] | Loss: 0.8926 | Acc: 64.99%\n",
      "\n",
      "Train Loss: 0.9789 | Train Acc: 65.10%\n",
      "Val Loss: 0.9568 | Val Acc: 65.57%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 65.57%)\n",
      "\n",
      "Epoch 4/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.8258 | Acc: 68.75%\n",
      "  Batch [100/313] | Loss: 0.7476 | Acc: 68.70%\n",
      "  Batch [200/313] | Loss: 0.6674 | Acc: 69.07%\n",
      "  Batch [300/313] | Loss: 0.7571 | Acc: 69.65%\n",
      "\n",
      "Train Loss: 0.8604 | Train Acc: 69.66%\n",
      "Val Loss: 0.7605 | Val Acc: 72.38%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 72.38%)\n",
      "\n",
      "Epoch 5/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 1.0071 | Acc: 66.41%\n",
      "  Batch [100/313] | Loss: 0.7154 | Acc: 72.65%\n",
      "  Batch [200/313] | Loss: 0.7217 | Acc: 73.26%\n",
      "  Batch [300/313] | Loss: 0.7870 | Acc: 73.44%\n",
      "\n",
      "Train Loss: 0.7680 | Train Acc: 73.50%\n",
      "Val Loss: 1.0378 | Val Acc: 67.89%\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 6/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.5931 | Acc: 81.25%\n",
      "  Batch [100/313] | Loss: 0.7783 | Acc: 75.46%\n",
      "  Batch [200/313] | Loss: 0.6817 | Acc: 75.56%\n",
      "  Batch [300/313] | Loss: 0.6739 | Acc: 75.84%\n",
      "\n",
      "Train Loss: 0.7045 | Train Acc: 75.89%\n",
      "Val Loss: 0.8247 | Val Acc: 71.59%\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 7/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.6272 | Acc: 79.69%\n",
      "  Batch [100/313] | Loss: 0.5987 | Acc: 78.74%\n",
      "  Batch [200/313] | Loss: 0.6076 | Acc: 78.01%\n",
      "  Batch [300/313] | Loss: 0.7883 | Acc: 78.21%\n",
      "\n",
      "Train Loss: 0.6418 | Train Acc: 78.21%\n",
      "Val Loss: 0.8345 | Val Acc: 72.06%\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 8/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.5473 | Acc: 83.59%\n",
      "  Batch [100/313] | Loss: 0.7033 | Acc: 79.96%\n",
      "  Batch [200/313] | Loss: 0.6481 | Acc: 79.57%\n",
      "  Batch [300/313] | Loss: 0.6017 | Acc: 79.95%\n",
      "\n",
      "Train Loss: 0.5997 | Train Acc: 79.92%\n",
      "Val Loss: 0.6707 | Val Acc: 77.17%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 77.17%)\n",
      "\n",
      "Epoch 9/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.5975 | Acc: 78.91%\n",
      "  Batch [100/313] | Loss: 0.5463 | Acc: 80.24%\n",
      "  Batch [200/313] | Loss: 0.5221 | Acc: 80.83%\n",
      "  Batch [300/313] | Loss: 0.4608 | Acc: 81.08%\n",
      "\n",
      "Train Loss: 0.5613 | Train Acc: 81.08%\n",
      "Val Loss: 0.6076 | Val Acc: 79.21%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 79.21%)\n",
      "\n",
      "Epoch 10/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.4079 | Acc: 84.38%\n",
      "  Batch [100/313] | Loss: 0.4986 | Acc: 82.63%\n",
      "  Batch [200/313] | Loss: 0.8472 | Acc: 82.16%\n",
      "  Batch [300/313] | Loss: 0.5795 | Acc: 82.12%\n",
      "\n",
      "Train Loss: 0.5288 | Train Acc: 82.12%\n",
      "Val Loss: 0.5890 | Val Acc: 79.58%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 79.58%)\n",
      "\n",
      "Epoch 11/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.6146 | Acc: 82.03%\n",
      "  Batch [100/313] | Loss: 0.5513 | Acc: 82.90%\n",
      "  Batch [200/313] | Loss: 0.4580 | Acc: 83.21%\n",
      "  Batch [300/313] | Loss: 0.6515 | Acc: 83.25%\n",
      "\n",
      "Train Loss: 0.5010 | Train Acc: 83.21%\n",
      "Val Loss: 0.5276 | Val Acc: 81.83%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 81.83%)\n",
      "\n",
      "Epoch 12/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.3614 | Acc: 87.50%\n",
      "  Batch [100/313] | Loss: 0.4267 | Acc: 84.11%\n",
      "  Batch [200/313] | Loss: 0.3860 | Acc: 84.08%\n",
      "  Batch [300/313] | Loss: 0.4488 | Acc: 83.92%\n",
      "\n",
      "Train Loss: 0.4785 | Train Acc: 83.95%\n",
      "Val Loss: 0.6873 | Val Acc: 76.05%\n",
      "Learning Rate: 0.001000\n",
      "\n",
      "Epoch 13/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.3215 | Acc: 90.62%\n",
      "  Batch [100/313] | Loss: 0.4930 | Acc: 84.58%\n",
      "  Batch [200/313] | Loss: 0.5909 | Acc: 84.34%\n",
      "  Batch [300/313] | Loss: 0.4437 | Acc: 84.53%\n",
      "\n",
      "Train Loss: 0.4580 | Train Acc: 84.53%\n",
      "Val Loss: 0.5205 | Val Acc: 82.46%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 82.46%)\n",
      "\n",
      "Epoch 14/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.2830 | Acc: 90.62%\n",
      "  Batch [100/313] | Loss: 0.4152 | Acc: 86.79%\n",
      "  Batch [200/313] | Loss: 0.4045 | Acc: 86.12%\n",
      "  Batch [300/313] | Loss: 0.4911 | Acc: 85.87%\n",
      "\n",
      "Train Loss: 0.4299 | Train Acc: 85.85%\n",
      "Val Loss: 0.5072 | Val Acc: 82.81%\n",
      "Learning Rate: 0.001000\n",
      "âœ“ Best model saved! (Val Acc: 82.81%)\n",
      "\n",
      "Epoch 15/30\n",
      "--------------------------------------------------------------------------------\n",
      "  Batch [0/313] | Loss: 0.4045 | Acc: 85.94%\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "num_epochs = 30\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Store metrics for plotting\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "learning_rates = []\n",
    "\n",
    "print(f\"Starting training for {num_epochs} epochs...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch, writer\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_preds, val_labels = validate(\n",
    "        model, val_loader, criterion, device, epoch, writer, 'Validation'\n",
    "    )\n",
    "    \n",
    "    # Update learning rate based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Train/LearningRate', current_lr, epoch)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "        }, 'best_cnn_model.pth')\n",
    "        print(f\"âœ“ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if current_lr < 1e-6:\n",
    "        print(\"\\nLearning rate too small. Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Training completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "writer.close()"
   ],
   "id": "859f6cbe72489906"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot Training Metrics"
   ],
   "id": "48a9a3dd1a62df07"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs_range = range(1, len(train_losses)+1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, train_losses, 'b-', label='Train Loss', marker='o', markersize=4)\n",
    "axes[0].plot(epochs_range, val_losses, 'r-', label='Val Loss', marker='s', markersize=4)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs_range, train_accs, 'b-', label='Train Acc', marker='o', markersize=4)\n",
    "axes[1].plot(epochs_range, val_accs, 'r-', label='Val Acc', marker='s', markersize=4)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate plot\n",
    "axes[2].plot(epochs_range, learning_rates, 'g-', marker='d', markersize=4)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training curves saved to 'cnn_training_curves.png'\")"
   ],
   "id": "69cca3d251f9c9ea"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Set Evaluation"
   ],
   "id": "d478bb444d555228"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('best_cnn_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_preds, test_labels = validate(\n",
    "    model, test_loader, criterion, device, 0, writer, 'Test'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compare with previous MLP\n",
    "print(\"\\nðŸ“Š Performance Comparison:\")\n",
    "print(f\"  CNN (this model): ~{test_acc:.1f}%\")\n",
    "print(f\"  MLP (previous):   ~50-55%\")\n",
    "print(f\"  Improvement:      ~{test_acc - 52.5:.1f}%\")"
   ],
   "id": "b6b1f4c728f036c1"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Per-Class Accuracy"
   ],
   "id": "b1e8eebf45bd1069"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "class_correct = defaultdict(int)\n",
    "class_total = defaultdict(int)\n",
    "\n",
    "for pred, label in zip(test_preds, test_labels):\n",
    "    if pred == label:\n",
    "        class_correct[label] += 1\n",
    "    class_total[label] += 1\n",
    "\n",
    "classes = test_dataset.classes\n",
    "\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "print(\"-\" * 50)\n",
    "class_accs = []\n",
    "for i, class_name in enumerate(classes):\n",
    "    acc = 100.0 * class_correct[i] / class_total[i]\n",
    "    class_accs.append(acc)\n",
    "    print(f\"{class_name:12s}: {acc:6.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
    "\n",
    "# Plot per-class accuracy\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(range(len(classes)), class_accs, color='steelblue', edgecolor='navy', linewidth=1.5)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Per-Class Accuracy on Test Set (CNN)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
    "plt.ylim([0, 100])\n",
    "plt.axhline(y=test_acc, color='r', linestyle='--', label=f'Overall Acc: {test_acc:.2f}%')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, class_accs):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_per_class_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPer-class accuracy plot saved to 'cnn_per_class_accuracy.png'\")"
   ],
   "id": "7427fb35c8930642"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Confusion Matrix"
   ],
   "id": "d9ceba73534ee1eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd', \n",
    "            xticklabels=classes, yticklabels=classes,\n",
    "            cbar_kws={'label': 'Count'}, linewidths=0.5)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.title('Confusion Matrix - CNN on CIFAR-10 Test Set', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Confusion matrix saved to 'cnn_confusion_matrix.png'\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(test_labels, test_preds, target_names=classes, digits=4))"
   ],
   "id": "c8b8706b8ab57f80"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Sample Predictions with Confidence"
   ],
   "id": "8009e81da014b427"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "model.eval()\n",
    "test_images, test_labels_batch = next(iter(test_loader))\n",
    "test_images_device = test_images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_images_device)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    confidences, predictions = probabilities.max(1)\n",
    "\n",
    "# Move to CPU for visualization\n",
    "test_images = test_images.cpu()\n",
    "predictions = predictions.cpu()\n",
    "confidences = confidences.cpu()\n",
    "\n",
    "# Visualize first 16 predictions\n",
    "fig, axes = plt.subplots(4, 4, figsize=(14, 14))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Denormalize image\n",
    "    img = test_images[i].permute(1, 2, 0).numpy()\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Color: green if correct, red if wrong\n",
    "    true_label = classes[test_labels_batch[i]]\n",
    "    pred_label = classes[predictions[i]]\n",
    "    confidence = confidences[i].item() * 100\n",
    "    \n",
    "    is_correct = test_labels_batch[i] == predictions[i]\n",
    "    color = 'green' if is_correct else 'red'\n",
    "    \n",
    "    ax.set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%', \n",
    "                 color=color, fontsize=9, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('CNN Predictions (Green=Correct, Red=Wrong)', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample predictions saved to 'cnn_sample_predictions.png'\")"
   ],
   "id": "27d32d86b57bde07"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Feature Maps Visualization"
   ],
   "id": "b63789ad728e1322"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature maps from first convolutional layer\n",
    "def visualize_feature_maps(model, image, layer_name='conv1'):\n",
    "    \"\"\"Visualize feature maps from a specific layer\"\"\"\n",
    "    \n",
    "    # Get the layer\n",
    "    if layer_name == 'conv1':\n",
    "        layer = model.conv1[0]  # First conv layer\n",
    "    elif layer_name == 'conv2':\n",
    "        layer = model.conv2[0]\n",
    "    elif layer_name == 'conv3':\n",
    "        layer = model.conv3[0]\n",
    "    \n",
    "    # Register hook to capture feature maps\n",
    "    activations = {}\n",
    "    def hook_fn(module, input, output):\n",
    "        activations['features'] = output.detach()\n",
    "    \n",
    "    handle = layer.register_forward_hook(hook_fn)\n",
    "    \n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(image.unsqueeze(0).to(device))\n",
    "    \n",
    "    handle.remove()\n",
    "    \n",
    "    return activations['features'].squeeze().cpu()\n",
    "\n",
    "# Get a sample image\n",
    "sample_img, sample_label = test_dataset[0]\n",
    "\n",
    "# Visualize feature maps from conv1\n",
    "feature_maps = visualize_feature_maps(model, sample_img, 'conv1')\n",
    "\n",
    "# Plot first 32 feature maps\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < feature_maps.shape[0]:\n",
    "        ax.imshow(feature_maps[i], cmap='viridis')\n",
    "        ax.set_title(f'Filter {i+1}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Feature Maps from First Convolutional Layer', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cnn_feature_maps.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Feature maps saved to 'cnn_feature_maps.png'\")"
   ],
   "id": "c4d6bcda3b2ce872"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "**Built a CNN** - Convolutional Neural Network with multiple conv blocks\n",
    "\n",
    "**Data Augmentation** - RandomFlip, RandomCrop, ColorJitter\n",
    "\n",
    "**Complete Training Pipeline** - Train, validation, and test\n",
    "\n",
    "**TensorBoard Logging** - Comprehensive metrics tracking\n",
    "\n",
    "**Advanced Features** - BatchNorm, Dropout, Adaptive LR\n",
    "\n",
    "**Comprehensive Evaluation** - Confusion matrix, per-class metrics\n",
    "\n",
    "**Feature Visualization** - Understanding learned representations\n",
    "\n",
    "### Performance Comparison:\n",
    "\n",
    "| Model | Test Accuracy | Parameters |\n",
    "|-------|--------------|------------|\n",
    "| **MLP** (Tutorial 3) | ~50-55% | ~1.7M |\n",
    "| **CNN** (This tutorial) | ~75-85% | ~1.5M |\n",
    "| **Improvement** | **+25-30%** | Fewer! |\n",
    "\n",
    "### Why CNN Performs Better:\n",
    "\n",
    "1. **Spatial Structure**: Preserves 2D image structure\n",
    "2. **Parameter Sharing**: Same filters applied across image\n",
    "3. **Translation Invariance**: Recognizes patterns anywhere\n",
    "4. **Hierarchical Features**: Low-level â†’ Mid-level â†’ High-level\n",
    "5. **Data Augmentation**: Artificially increases training data\n",
    "\n",
    "### Architecture Insights:\n",
    "\n",
    "```\n",
    "Input (3x32x32)\n",
    "    â†“\n",
    "Conv Block 1: 3â†’64 channels (32x32 â†’ 16x16)\n",
    "    â†“\n",
    "Conv Block 2: 64â†’128 channels (16x16 â†’ 8x8)\n",
    "    â†“\n",
    "Conv Block 3: 128â†’256 channels (8x8 â†’ 4x4)\n",
    "    â†“\n",
    "Global Avg Pool â†’ Flatten\n",
    "    â†“\n",
    "FC Layers: 256 â†’ 512 â†’ 10 classes\n",
    "```\n",
    "\n",
    "### Key Techniques Used:\n",
    "\n",
    "- **Batch Normalization**: Stabilizes training\n",
    "- **Dropout**: Prevents overfitting\n",
    "- **Data Augmentation**: Improves generalization\n",
    "- **Adaptive LR**: ReduceLROnPlateau scheduler\n",
    "- **Global Average Pooling**: Reduces parameters\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Try ResNet, VGG, or other architectures\n",
    "- Experiment with transfer learning\n",
    "- Try different augmentation strategies\n",
    "- Implement attention mechanisms\n",
    "- Use mixed precision training for speed\n",
    "\n",
    "### TensorBoard Commands:\n",
    "\n",
    "```bash\n",
    "# View training logs\n",
    "tensorboard --logdir=runs\n",
    "\n",
    "# Compare multiple runs\n",
    "tensorboard --logdir=runs --port=6006\n",
    "```"
   ],
   "id": "d29695fc0a0d2086"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
