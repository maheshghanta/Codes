{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning with VGG16\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maheshghanta/Codes/blob/master/PyTorch_Tutorials/5.Transfer_Learning.ipynb)\n",
    "\n",
    "This tutorial demonstrates **Transfer Learning** using pre-trained VGG16 for CIFAR-10 classification:\n",
    "- Using VGG16 pre-trained on ImageNet as feature extractor\n",
    "- Freezing convolutional layers\n",
    "- Training only the classifier head\n",
    "- Complete pipeline with TensorBoard logging\n",
    "- Performance comparison with models from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview: Transfer Learning\n",
    "\n",
    "**What is Transfer Learning?**\n",
    "- Use knowledge from one task to solve another\n",
    "- Leverage pre-trained models on large datasets (ImageNet)\n",
    "- Fine-tune for your specific task\n",
    "\n",
    "**Why Transfer Learning?**\n",
    "- ✅ **Faster training**: Pre-trained features\n",
    "- ✅ **Better accuracy**: Especially with limited data\n",
    "- ✅ **Less data needed**: Features already learned\n",
    "- ✅ **Proven architecture**: Battle-tested on ImageNet\n",
    "\n",
    "**VGG16 Architecture:**\n",
    "- 13 convolutional layers\n",
    "- 3 fully connected layers\n",
    "- Pre-trained on 1.2M ImageNet images (1000 classes)\n",
    "- We'll use it as a **feature extractor**\n",
    "\n",
    "**Our Approach:**\n",
    "1. Load pre-trained VGG16\n",
    "2. **Freeze** all convolutional layers (no training)\n",
    "3. Replace classifier for 10 classes (CIFAR-10)\n",
    "4. Train **only** the new classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Torchvision version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "**Important**: VGG16 expects images normalized with ImageNet mean/std!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 expects 224x224 images and specific normalization\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(224),  # VGG16 expects 224x224\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load CIFAR-10\n",
    "train_dataset_full = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=test_transform\n",
    ")\n",
    "\n",
    "# Split: 80% train, 20% validation\n",
    "train_size = int(0.8 * len(train_dataset_full))\n",
    "val_size = len(train_dataset_full) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    train_dataset_full,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "print(f\"Classes: {test_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64  # Smaller batch for larger images\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Check data shape\n",
    "sample_image, sample_label = next(iter(train_loader))\n",
    "print(f\"Batch shape: {sample_image.shape}\")  # Should be (batch_size, 3, 224, 224)\n",
    "print(f\"Label shape: {sample_label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Pre-trained VGG16 and Modify\n",
    "\n",
    "We'll:\n",
    "1. Load VGG16 pre-trained on ImageNet\n",
    "2. Freeze all convolutional layers\n",
    "3. Replace the classifier for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16\n",
    "print(\"Loading pre-trained VGG16...\")\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "print(\"✓ VGG16 loaded successfully!\\n\")\n",
    "\n",
    "# Show original architecture\n",
    "print(\"Original VGG16 Architecture:\")\n",
    "print(vgg16)\n",
    "\n",
    "# Count original parameters\n",
    "total_params = sum(p.numel() for p in vgg16.parameters())\n",
    "print(f\"\\nTotal parameters in VGG16: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all convolutional layers (features)\n",
    "print(\"Freezing convolutional layers...\")\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"✓ All convolutional layers frozen!\")\n",
    "\n",
    "# Check which layers are frozen\n",
    "frozen_params = sum(p.numel() for p in vgg16.features.parameters())\n",
    "print(f\"Frozen parameters: {frozen_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the classifier for CIFAR-10 (10 classes)\n",
    "# Original VGG16 classifier is for ImageNet (1000 classes)\n",
    "\n",
    "print(\"\\nOriginal classifier:\")\n",
    "print(vgg16.classifier)\n",
    "\n",
    "# Create new classifier\n",
    "num_features = vgg16.classifier[0].in_features  # 25088\n",
    "\n",
    "vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 4096),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(4096, 1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(1024, 10)  # 10 classes for CIFAR-10\n",
    ")\n",
    "\n",
    "print(\"\\n✓ New classifier for CIFAR-10:\")\n",
    "print(vgg16.classifier)\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum(p.numel() for p in vgg16.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in vgg16.parameters())\n",
    "\n",
    "print(f\"\\nParameter Summary:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"  Percentage trainable: {100 * trainable_params / total_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup Training Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Move model to device\n",
    "model = vgg16.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer - only for trainable parameters!\n",
    "optimizer = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()),  # Only trainable params\n",
    "    lr=0.001,\n",
    "    weight_decay=1e-4\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    ")\n",
    "\n",
    "print(f\"Loss function: {criterion}\")\n",
    "print(f\"Optimizer: {optimizer.__class__.__name__}\")\n",
    "print(f\"Initial learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup TensorBoard Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorBoard writer\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "log_dir = f'runs/vgg16_transfer_{timestamp}'\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "print(f\"TensorBoard logs saved to: {log_dir}\")\n",
    "print(f\"To view: tensorboard --logdir=runs\")\n",
    "\n",
    "# Log model architecture\n",
    "sample_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "writer.add_graph(model, sample_input)\n",
    "print(\"Model graph added to TensorBoard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device, epoch, writer):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Log batch metrics\n",
    "        if batch_idx % 50 == 0:\n",
    "            writer.add_scalar('Train/BatchLoss', loss.item(), epoch * len(loader) + batch_idx)\n",
    "            batch_acc = 100. * correct / total\n",
    "            writer.add_scalar('Train/BatchAccuracy', batch_acc, epoch * len(loader) + batch_idx)\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'  Batch [{batch_idx}/{len(loader)}] | '\n",
    "                      f'Loss: {loss.item():.4f} | Acc: {batch_acc:.2f}%')\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, criterion, device, epoch, writer, phase='Validation'):\n",
    "    \"\"\"\n",
    "    Validate the model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = running_loss / len(loader)\n",
    "    accuracy = 100. * correct / total\n",
    "    \n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalar(f'{phase}/Loss', avg_loss, epoch)\n",
    "    writer.add_scalar(f'{phase}/Accuracy', accuracy, epoch)\n",
    "    \n",
    "    return avg_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "print(\"Training functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Loop\n",
    "\n",
    "Transfer learning typically converges much faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 15  # Fewer epochs needed for transfer learning\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Store metrics\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "learning_rates = []\n",
    "\n",
    "print(f\"Starting transfer learning for {num_epochs} epochs...\")\n",
    "print(\"Note: Transfer learning converges faster than training from scratch!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch, writer\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_preds, val_labels = validate(\n",
    "        model, val_loader, criterion, device, epoch, writer, 'Validation'\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    writer.add_scalar('Train/LearningRate', current_lr, epoch)\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "    learning_rates.append(current_lr)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nTrain Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "        }, 'best_vgg16_transfer.pth')\n",
    "        print(f\"✓ Best model saved! (Val Acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if current_lr < 1e-7:\n",
    "        print(\"\\nLearning rate too small. Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Training completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Plot Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "epochs_range = range(1, len(train_losses)+1)\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(epochs_range, train_losses, 'b-', label='Train Loss', marker='o', markersize=5)\n",
    "axes[0].plot(epochs_range, val_losses, 'r-', label='Val Loss', marker='s', markersize=5)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Transfer Learning: Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[1].plot(epochs_range, train_accs, 'b-', label='Train Acc', marker='o', markersize=5)\n",
    "axes[1].plot(epochs_range, val_accs, 'r-', label='Val Acc', marker='s', markersize=5)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy (%)', fontsize=12)\n",
    "axes[1].set_title('Transfer Learning: Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].axhline(y=85, color='g', linestyle='--', alpha=0.5, label='Target: 85%')\n",
    "\n",
    "# Learning rate\n",
    "axes[2].plot(epochs_range, learning_rates, 'g-', marker='d', markersize=5)\n",
    "axes[2].set_xlabel('Epoch', fontsize=12)\n",
    "axes[2].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[2].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('VGG16 Transfer Learning on CIFAR-10', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('vgg16_transfer_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Training curves saved to 'vgg16_transfer_curves.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load('best_vgg16_transfer.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"Best validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_acc, test_preds, test_labels = validate(\n",
    "    model, test_loader, criterion, device, 0, writer, 'Test'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Performance Comparison\n",
    "\n",
    "Let's compare VGG16 transfer learning with our previous models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance comparison\n",
    "models_comparison = {\n",
    "    'Model': ['MLP\\n(Tutorial 3)', 'Custom CNN\\n(Tutorial 4)', 'VGG16 Transfer\\n(This Tutorial)'],\n",
    "    'Accuracy': [52, 78, test_acc],  # Approximate values\n",
    "    'Params': ['1.7M', '1.5M', f'{trainable_params/1e6:.1f}M trainable\\n({total_params/1e6:.1f}M total)'],\n",
    "    'Training Time': ['20 epochs', '30 epochs', f'{len(train_losses)} epochs'],\n",
    "    'Advantages': [\n",
    "        'Simple,\\nFast training',\n",
    "        'Better than MLP,\\nFewer params',\n",
    "        'Best accuracy,\\nPre-trained features'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create comparison plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Accuracy comparison\n",
    "accuracies = [52, 78, test_acc]\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "bars = ax1.bar(range(3), accuracies, color=colors, edgecolor='black', linewidth=2)\n",
    "ax1.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(3))\n",
    "ax1.set_xticklabels(['MLP', 'Custom CNN', 'VGG16\\nTransfer'], fontsize=10)\n",
    "ax1.set_ylim([0, 100])\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "ax1.axhline(y=85, color='g', linestyle='--', linewidth=2, label='Excellent (85%)')\n",
    "ax1.legend()\n",
    "\n",
    "# Add value labels\n",
    "for i, (bar, acc) in enumerate(zip(bars, accuracies)):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Add improvement percentage\n",
    "    if i > 0:\n",
    "        improvement = acc - accuracies[0]\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height/2,\n",
    "                 f'+{improvement:.1f}%', ha='center', va='center', \n",
    "                 fontsize=10, color='white', fontweight='bold')\n",
    "\n",
    "# Training efficiency comparison\n",
    "epochs_list = [20, 30, len(train_losses)]\n",
    "bars2 = ax2.bar(range(3), epochs_list, color=colors, edgecolor='black', linewidth=2)\n",
    "ax2.set_xlabel('Model', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Epochs to Converge', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Training Efficiency', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks(range(3))\n",
    "ax2.set_xticklabels(['MLP', 'Custom CNN', 'VGG16\\nTransfer'], fontsize=10)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, epochs in zip(bars2, epochs_list):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{epochs} epochs', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 PERFORMANCE SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Model':<20} {'Accuracy':<15} {'Improvement':<15} {'Epochs'}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'MLP':<20} {52:>6.1f}%        {'Baseline':<15} {20}\")\n",
    "print(f\"{'Custom CNN':<20} {78:>6.1f}%        {'+26.0%':<15} {30}\")\n",
    "print(f\"{'VGG16 Transfer':<20} {test_acc:>6.1f}%        {f'+{test_acc-52:.1f}%':<15} {len(train_losses)}\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n🏆 Winner: VGG16 Transfer Learning!\")\n",
    "print(f\"   - Highest accuracy: {test_acc:.2f}%\")\n",
    "print(f\"   - Fastest convergence: {len(train_losses)} epochs\")\n",
    "print(f\"   - Leverages pre-trained features from ImageNet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Per-Class Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-class accuracy\n",
    "from collections import defaultdict\n",
    "\n",
    "class_correct = defaultdict(int)\n",
    "class_total = defaultdict(int)\n",
    "\n",
    "for pred, label in zip(test_preds, test_labels):\n",
    "    if pred == label:\n",
    "        class_correct[label] += 1\n",
    "    class_total[label] += 1\n",
    "\n",
    "classes = test_dataset.classes\n",
    "\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "print(\"-\" * 50)\n",
    "class_accs = []\n",
    "for i, class_name in enumerate(classes):\n",
    "    acc = 100.0 * class_correct[i] / class_total[i]\n",
    "    class_accs.append(acc)\n",
    "    print(f\"{class_name:12s}: {acc:6.2f}% ({class_correct[i]}/{class_total[i]})\")\n",
    "\n",
    "# Plot per-class accuracy\n",
    "plt.figure(figsize=(14, 6))\n",
    "bars = plt.bar(range(len(classes)), class_accs, color='mediumseagreen', edgecolor='darkgreen', linewidth=1.5)\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.title('Per-Class Accuracy - VGG16 Transfer Learning', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
    "plt.ylim([0, 100])\n",
    "plt.axhline(y=test_acc, color='r', linestyle='--', linewidth=2, label=f'Overall: {test_acc:.2f}%')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, class_accs):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{acc:.1f}%', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('vgg16_per_class_accuracy.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPer-class accuracy plot saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=classes, yticklabels=classes,\n",
    "            cbar_kws={'label': 'Count'}, linewidths=0.5)\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.title('Confusion Matrix - VGG16 Transfer Learning', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('vgg16_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(test_labels, test_preds, target_names=classes, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Sample Predictions with Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test images\n",
    "model.eval()\n",
    "test_images, test_labels_batch = next(iter(test_loader))\n",
    "test_images_device = test_images.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_images_device)\n",
    "    probabilities = torch.softmax(outputs, dim=1)\n",
    "    confidences, predictions = probabilities.max(1)\n",
    "\n",
    "# Move to CPU\n",
    "test_images = test_images.cpu()\n",
    "predictions = predictions.cpu()\n",
    "confidences = confidences.cpu()\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(4, 4, figsize=(14, 14))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    # Denormalize\n",
    "    img = test_images[i].permute(1, 2, 0).numpy()\n",
    "    img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    \n",
    "    # Labels\n",
    "    true_label = classes[test_labels_batch[i]]\n",
    "    pred_label = classes[predictions[i]]\n",
    "    confidence = confidences[i].item() * 100\n",
    "    \n",
    "    is_correct = test_labels_batch[i] == predictions[i]\n",
    "    color = 'green' if is_correct else 'red'\n",
    "    \n",
    "    ax.set_title(f'True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.1f}%', \n",
    "                 color=color, fontsize=9, fontweight='bold')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('VGG16 Transfer Learning Predictions\\n(Green=Correct, Red=Wrong)', \n",
    "             fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.savefig('vgg16_sample_predictions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample predictions saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Final Results:\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Test Accuracy** | ~85-90% |\n",
    "| **Training Epochs** | 15 (vs 30 for custom CNN) |\n",
    "| **Trainable Parameters** | ~21M (vs 138M total) |\n",
    "| **Improvement over MLP** | +35-38% |\n",
    "| **Improvement over Custom CNN** | +7-12% |\n",
    "\n",
    "### Why Transfer Learning Works:\n",
    "\n",
    "1. **Pre-trained Features**: VGG16 learned general image features on ImageNet\n",
    "2. **Feature Reusability**: Low-level features (edges, textures) transfer well\n",
    "3. **Less Data Needed**: Don't need millions of images\n",
    "4. **Faster Training**: Only train classifier, not entire network\n",
    "5. **Better Generalization**: Pre-trained features are robust\n",
    "\n",
    "### Transfer Learning Strategies:\n",
    "\n",
    "**1. Feature Extraction (What we did)**\n",
    "- Freeze all pre-trained layers\n",
    "- Train only new classifier\n",
    "- Best when: Limited data, similar task\n",
    "\n",
    "**2. Fine-tuning (Advanced)**\n",
    "- Unfreeze some layers\n",
    "- Train with very low learning rate\n",
    "- Best when: More data available\n",
    "\n",
    "**3. Full Training**\n",
    "- Use pre-trained weights as initialization\n",
    "- Train entire network\n",
    "- Best when: Large dataset, different task\n",
    "\n",
    "### When to Use Transfer Learning:\n",
    "\n",
    "✅ **Use transfer learning when:**\n",
    "- Limited training data\n",
    "- Similar domain (images → images)\n",
    "- Want faster training\n",
    "- Want better accuracy\n",
    "- Limited computational resources\n",
    "\n",
    "❌ **Don't use transfer learning when:**\n",
    "- Very different domain (text → images)\n",
    "- Extremely large custom dataset\n",
    "- Very specific features needed\n",
    "- Computational resources unlimited\n",
    "\n",
    "### Popular Pre-trained Models:\n",
    "\n",
    "- **VGG16/VGG19**: Simple, deep, good baseline\n",
    "- **ResNet50/101**: Deeper, better accuracy\n",
    "- **EfficientNet**: Best accuracy/efficiency trade-off\n",
    "- **MobileNet**: Lightweight, for mobile devices\n",
    "- **Vision Transformer**: State-of-the-art\n",
    "\n",
    "\n",
    "### TensorBoard Commands:\n",
    "\n",
    "```bash\n",
    "# View all runs together\n",
    "tensorboard --logdir=runs\n",
    "\n",
    "# Compare: MLP vs CNN vs Transfer Learning\n",
    "tensorboard --logdir=runs --port=6006\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
